### Week 1
- CC is a paradigm for arranging it resources.
- Business Drivers:
	- Capacity planning
	- organizational agility
	- cost reduction.

### Week 2
- A resource can be virtual or physical IT-artifact
- It resource that is on-prem cannot be cloud based and visa-versa.
- 5 essential characteristics
	- On-demand self-service
	- ubiquitous
	- multitenancy
	- elasticity
	- Measured service
	- resiliency 
- Service models/delivery models: saas, paas, iaas, faas, XAAS(not 3-4, there are many)
- Deployment models: private, public, multi, hybrid cloud
- Key enabling technlogies:
	- fast wide-area networks
	- powerful, inexpensive server computers
	- high-performance virtualization for commodity hardware.
- openstack is private cloud.
- Cloud != internet, cloud have boundary
- scale out quickly and scale in slowly.
- ![[Pasted image 20230622163309.png]]
- Cloud consumer: person or organization
- Cloud service consumer: an application assume roles and access cloud service.
- Cloud provider(aws) can have services hosted on it which are built by IBM(cloud service owner of that API).
- ![[Pasted image 20230622171005.png]]
- Multitenancy:
	- characteristics where soft is shared among tenants and all are isolated from each other.
- resileicnncy:
	- form of failover that can distribute redundant implementations of it resources. for reliability and availability. can have multi cloud as well
- buying: high upfront cost.
- leasing: high long-term cost.
- in Cloud:
	- geographically diverse: reliability/availability
	- apocalyse safe infra: reliability
	- redundancy: reliability
	- advanced network attache storage (NAS): availabiitity
- Benefits/risks:
	- increased scalability
	- increased availability/reliability
	- regular updates
	- reduce investment and proportional costs
	- increased security
	- and vulnerabilities/reduced governance
	- limited portability
	- multi-regional compliance and legal issues
	- ethical issues.
		- if breach happens: whos responsible, cos that is shared 50/50, who will customer blame.
		- environmental impacts
- 
### Week 3
- Cloud computing is ubiquitous and is accessible via multiple protocols over internet.
- Cloud providers buy more ISP and negotiate.
- Data Centers:
	- A "rack" consists of ~48 servers connected to an ethernet switch, the switch connects to a cell
	- A cell/array consists of several racks, the racks in a cell are connected by an array switch
	- A Warehouse Scale Computer (WSC)(backbone of cloud infra) is a cluster comprised of tens of thousands of servers(50k to 100k processors)
	- A cluster is a collection of desktop computers or servers connected together by a local area network to act as a single larger computer
	- To build data center:
		- $600 to $1,100 = per gross square foot
		- $7 million to $12 = million per megawatt of commissioned IT load
- Automate Data centers:
	- provision resources: chef and puppet(for batch of servers).
	- fault detection and recovery
	- replication.
	- Cant go in data center(very rare), so remote access via head node(have several network cards, for public internet, data transfer,.. other).
- Availability:
	- 5 9s is bench mark for mission critical systems
	- it means system is up/available 99.999% of the time.
	- it is reliability number.
- Availability vs Reliability:
	- Availability, or the amount of time a system is up and functioning properly, is another term associated with reliability in cloud computing. While availability is measured in terms of time loss, reliability is measured in terms of the number and impact of failures. Reliability may be seen as a measure of availability.
- Resiliency: ability to fault tolerance
- Security:
	- Physical and software
		- motion sensor, biometric, 24 hour surveillance
	- Least privilege
	- hardware decommission policies.
- CPU:
	- Server blade: a big server has everything, memory, network, everything ~96 processors.
- Memory:
	- ECC(error correction code) Ram: with HPC computer, we have ECC ram.
- Storage:
	- Data centers have specialized storage systems.
	- their hard disk are arranged into arrays.
	- Redundant Arrays of Independent Disks (RAID) hard disk arrays
	- controllers have massive cache- faster read and write
	- removable without power down
	- fast data replication- volume cloning, snapshotting(there is sync happening here)
	- NAS: Network Attached Storage
		- Arrays can be connected to network device using NFS(like efs) and SMB.
	- Cloud also provide reliability by replicating to multiple regions
	- Robot controlled tape libraries(archive purpose for disaster recovery) provide cost-effective cold storage for big data / backup
- GPU:
	- has lot of cores: ~10k cores
	- CPU-latency
	- GPU-throughput, can do parallel
- Virtualization:
	- server,storage,network,power
	- VM do share hosts but are isolaed with some risks.
	- software on vm are not awar of virtulization.
	- Virtualization enables both horizontal AND vertical scaling
	- Benefits of virtualization [2]  
		• Reduced capital and operation costs;  
		• Minimized or eliminated downtime;  
		• Increased IT productivity, efficiency, agility and responsiveness;  
		• Faster provisioning of applications and resources;  
		• Greater business continuity and disaster recovery;  
		• Simplified data center management;  
		• Availability of a true Software-Defined Data Center: IaaC
	- Characteristics: partitioning(partition the hardware), encapsulation(we save the state of VM in files, so they are moveable) ,isolation, hardware independence
	- VMM = virtual machine manager, Hypervisor
	- types:
		- bare metal (native architecture): Hyper-V, Xen, VMWare ESX: cloud
			- HV on top of hardware
			- Pros: faster interaction with hardware, no fee for host OS license and IT resource.
			- Cons: compatible with hardware devices, reduced driver support mitigated by commodity hardware.
		- hosted architecture: Virtual PC & Virtual Server, VMware Workstation, KVM: personal use, 
			- HV on top of OS
			- Pros: more customize, backup recovery, security mngmnt, directory services (roles & permissions)
			- Cons: more latency hardware, OS `$$`, OS resource consume.
		![[Pasted image 20230624013812.png]]
	- How to virtulize:
		- Multiplex: paging
		- aggregation: RAID
		- emulation: swap
- Container: ecf2, beanstalk, eks, ecs can be used to deploy containers
	- read-only, need to change image to change it.
	- Why better than VM:
		- faster scaling, cheaper, lighter
		- better security, immutable
		- faster boot time
		- can be used with IaaS
		- ![[Pasted image 20230624020608.png]]

### Week 4
Cloud Delivery model:
- it is a prepackaged combination of it resources.
SOA:
- SOA breaks up the whole application into separate service modules(interoperable, reusable) that interact with one another to carry out the specific business objectives.
- ![[Pasted image 20230624182429.png]]
- IaaS![[Pasted image 20230624182839.png]]
- PaaS
- Why would a cloud consumer choose this model?
	- To extend on-premise environments into the cloud for scalability and economic purpose
	- To entirely substitute an on-premise environment
	- To become a cloud provider and deploy their own cloudservices to be made available to other cloud consumers, for example:
	- Twilio
	- AWS Elastic Beanstalk, Sagemaker
- ![[Pasted image 20230624183507.png]]
- SaaS:
- ![[Pasted image 20230624183704.png]]
- FaaS
- ![[Pasted image 20230624184133.png]]
- All
- ![[Pasted image 20230624184354.png]]
- ![[Pasted image 20230624184518.png]]
- Cloud Deployment model:
	- distinguished by: size, access, ownership, location
	- types: public, private, multi, hybrid, vpc
	- ![[Pasted image 20230627111558.png]]

### Week 5
- Artifact registry:
	- new, more functionality & benefits, same as container registry and more, fully-managed
- Types of deployment in K8s:
	- traditional: apps on os
	- virtualizd deployment: apps in VM
	- container: continer runtime on top of host os, and it contains containers
	- 2nd and 3rd can work together.
- tools for containers:
	- ecs, eks, gke
- k8s:
	- service discovery and load balancing
	- storage orchestration
	- automated rollouts and rollbacks
	- auto bin packing
	- self healing
	- secret adn configuratyion managment.
- K8s features:
	- rollback to 10 versions of app
	- ![[Pasted image 20230625232349.png]]
- Very small shouldnt use K8s, it is expensive and wont be worth it.
- Cloud shell:
	- 5gb space in home dir
	- 50 hrs /week
- K8s Objects:
	- a persistent entity representing the object spec: desired state and object status: current state. like pods, nodes
- Workload objects:
	- CronJob
	- Replicaset
	- job
	- pods
- replicaset === no of pods
- pods NOT containers are smallest deployment unit in k8s
- Control plane: Can havee multiple master node for high availability.
	- kube api server: hub for cluster, connect everything
	- controller manager: collection of managers, manage resources netowkr, compute resources.
	- scheduler: assign pods to right nodes, check nodes status health.
	- etcd: contain all data, metadata, config, status data
	- kubelet == why we need? cos master node can be changed to worker node, in most case we dont do it, there is a way to make it or prevent it from being worker node.
	- kubecloud manager: we need it if k8s is on cloud allows it to connect to gcp
- Data plane:
	- Nodes === virtual machines, worker node
	- one node can have 110 pods by default.
	- kubelet = component work between pod and container, it deploys container on pods.
	- kubeproxy: networking service, within and outside cluster, networking rules
	- container runtime: we have it by default, cos we chose container-optimized OS for node while creating cluster, nginx pod??
- For gcp:
	- controller manager == resource manager
	- storage == etcd
- cluster is in default network vpc.
- Optional in gke:
	- pv
	- cloud operations
	- load balancer
- two kinds of cluster:s
	- autopilot: not flexible but convenient, managed by gke
	- standard: we manage nodes.
- Default number of nodes is 3 on cluster by default, can change while cluster is running
- we can have node pools, for different kind of nodes we can have diff pools
- by defailt there is a pool with 3 nodes.
- for ex: dev test pool.
- cluster is by default zonal, it can be regional.
- when regional there are 3 clusters by default in each zone with 3 nodes in each cluster, can be modified.
- system will keep nodes same in all zones, change in one zone, system reflects changs everywhere.
- Workflow when we run/submit yaml file to k8s.
	- api server and other components in control plane will understand yaml file.
- Lifecycle of pod:
	- ![[Pasted image 20230626024044.png]]
	- crashloopbackoff: dont have enough space, type in yaml file, nop img found, covers very broad errors,has error code.	- 
- kubectl: 
	- call kube-apiserver via https
	- $HOME/.kube/cofig: target cluster name, credentials for cluster(clusters are listed in case of multiple clusters).
	- when we run it on cloudshell.
	- uses:
		- create/view/delete objects
		- view and export configurations.
		- 
- Commands
	- kubectl get pods
		- we get error code.
	- kubectl config view
	- gcloud container clusters get credentials `<name>` --zone `<name>`.
		- gclouyd is for interacting with GKE, to get cluster and credentials.
		- kubectl is for interacting within k8s.
	- kubectl get pods name -o=yaml
	- kubectl get pods -o=wide
	- kubectl exec -it webserver /bin/bash
		- df -h == all thing taken place and running inside pods.
		- interactive terminal = -it
	- kubectl exec -it `<pod-name>` -c `<container-name>` -- /bin/bash
		- in case it has multiple containers running.
	- kubectl logs `podname`
	- kubectl describe deployment `name`
- Deployments, job, scaling
	- deployments declrare the state of pods.
	- for stateful workload we need == statefulset
	- deployment
		- k8s can scale and autoscale
			- autoscale is not setp by default.
		- rollback pods to previous version
		- rollouts updates to pods.
		- workload for deployment is stateless
		- workload process:
			- when deployment is intalled on lcuster
				- processing state: 
				- compoelete state: all pods in running state
				- failed state: can be many things
			- deployment controller controlls the pods/objects.
			- manager will keep the desired adncurrent status of objects.
		- how to create:
			- kubectl apply -f .yaml // -f is for filename
			- kubectl create deployment ...
			- console.
		- behind the scenes of updating deployment:
			- pods are gradually moved from older replicaset to newer replicaset.
		- strategy: type recreate (just under replicas), it will delete old and then deploy new replicas.
			- 'read all deployment strtaegiesL A/B, cancary, in table.'
	- Service:
		- cluser ip
		- node port
		- load balancer
	- Jobs:
		- like a abatch
		- completetions: 3, run 3 jobs parallally.
		- can be scaled
		- whenn job is done, container s gone and pod as well
			- if eant to keep pod: --cascade false
		- deployment  vs jhob:
			- is how they handle pod that is terminated.
			- deployment tryies to restart the pod andmatch desired number.
			- default value of restart policy in deployment is: always
			- Job never restart contaione, once compoleted done.
	- Scale clusters:
		- manyally scale or autoscale
		- gcloud will be used we are scaling cluster not any object inside cluster
		- we can change numer of nodes using this
		- if scale down, it randomly chose odes and cloe them even if job running on them: autoscaler remove nodes with <50% utilization.
		- node scaling = corased grained
		- pod scaling = fine grained
	- Helm:
		- can interact with API server.
	- Storage:
		- ephemral: can be mount on top of pod.
			- emptyDir: is inside pod shared by all containers
				- created automatically when pod is assigned to node.,
			- configmap,secret, downloadAPI
		- PV:
			- PD created b cluster admin, can be done by terraform of gcloud.
				- compute disk create 
			- devs can caliom those pds and use them mount them on thier pods..
			- PVC creatio cannot be skipped, PV can be skipped, PVC cant find PV, it creates one.
			- readwriteonce: both opertions on on node.
			- readonlymany: read for many nodes.
			- readwritemany: cannot work, cannot mount a pv on multipe nodes.
		- PVC:
			- pvc is removed, pv is removed.
			- but what to retain pv: persisentVIolumeReclaimPolicy
### Week 6 
Mechanism refresh:
- building blocks core services, api, frameworks etc to build tech in cloud
- storage, compute, serverless computing(SQS), network, security
Resource cluster:
- take and group mechanism
- two types and major reasons to do load balancing
	- Load balancer cluster
	- HA cluster
- Server cluster:
	- physical or virtual server cluster
	- VIM moves VM from one to another physical server when physical is overloaded., physicals have shared storage.
- Database Cluster:
	- for performance and availability
	- they are synchronous many ways to do that (sometimes via transactional logs).
- Large Dataset cluster:
	- large data, split them clean them and spread them across nodes.
	- hadoop
- Objective for architecture:
	- availability, performance, data integrity and security.
- Fundamental architecture:
	- Workload distribution
		- usually uses round robin to distribute load
		- aggregation.
		- benefits:
			- all resources use equally
			- no one sits idle, balancer load stuff equally.
			- turn things off and on on demand, only in and out??
		- need to consider sticky vs non-sticky sessions.
	- Dynamic Scalability architecture:
		- uses automatic scaling listener and resource replication(uses some sort IaaC).
		- like beanstalk
		- benefits:
			- scale in and out, up and down
			- automatic disaster recovery
		- need to setup automatic scaling listener
	- Resource pool architecture:
		- dynamic scaling architecture need time to spin up architecture.
		- size of the pool is fixed.??
		- need synchronization across pools
		- benefits:
			- mostly used reservation pricing discounts
			- high level control on distribution,(in other we treat every resource equally)
	- Cloud burst architecture:
		- automatic scaling listener spin up, replicate resource and spin down when needed.
		- benefits:
			- bridging technique: transition to the cloud.
			- hybrid implementations
	- Elastic disk provision architecture:
		- dynamic storage provisioning
		- billed for what we use.
	- Dynamic data normalization architecture
		- not storing data unnecessarily.
		- redundant blocks are replaced with pointers
		- de-duplication system
	- Redundant storage architecture
		- uses raid to replicate data locally.
		- but can be used to diverse globally and reliability.
	- Load balanced virtual server instance architecture
		- we can balance services but what about server themselves.
		- with watchdog system and load balancer it does balance physical servers, live VM migration.
	- Non disruptive service architecture:
		- have some sort of triggers
		- replicate or migrate the implementation causing in disruption
		- temporary solutions that diverts traffic to new 
	- Cloud Balancing architecture
		- highest:
			- performance and scalability of it resources
			- availability reliability
			- Cost
	- Rapid provisioning architecture:
		- like launching from a tempalate


### Questions:
1. examples where vertical scaling is required
3. youtube design
4. reosurce cluster
5. cons of cloud