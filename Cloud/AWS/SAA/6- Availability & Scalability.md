> High availability usually means running on at least 2 AZs

ELB:
> ELB uses security groups as well.
Benefits:
1. Spread load across multiple downstream instances
2. Expose a single point of access (DNS) to your application
3. Seamlessly handle failures of downstream instances
4. Do regular health checks to your instances
5. Provide SSL termination (HTTPS) for your websites
6. Enforce stickiness with cookies
7. High availability across zones
8. Separate public traffic from private traffic

Can be integrated with:
- EC2, EC2 Auto Scaling Groups, Amazon ECS 
- AWS Certificate Manager (ACM), CloudWatch 
- Route 53, AWS WAF, AWS Global Accelerator

Health Check:
- The health check is done on a port and a route (/health is common)
- If the response is not 200 (OK), then the instance is unhealthy

Load Balancer Types:
1. **Classic Load Balancer (CLB):** Supports HTTP, HTTPS, TCP, and SSL.
2. **Application Load Balancer (ALB):** Supports HTTP, HTTPS, and WebSocket.
3. **Network Load Balancer (NLB):** Supports TCP, TLS (secure TCP), and UDP.
4. **Gateway Load Balancer (GWLB):** Operates at layer 3 (Network layer) - IP Protocol.

> load balancers can be configured as internal (private) or external (public) ELBs.

**Application Load balancer:** Layer 7 only
Capabilities:
- Load balancing to multiple HTTP applications across machines (target groups)
- Load balancing to multiple applications on the same machine (ex: containers)
- Support for HTTP/2 and WebSocket
- Support redirects (from HTTP to HTTPS for example)
- Routing based on url path/hostnames/query/http headers to different target groups.
- port mapping.
- DONT have static IPs
- ALB cant point to ALB.
Great for:
1. microservices and container based apps
What are target groups:
1. EC2 instances (can be managed by an Auto Scaling Group) – HTTP
2. ECS tasks (managed by ECS itself) – HTTP
3. Lambda functions – HTTP request is translated into a JSON event
4. Private IP Addresses

>ALB can route to multiple target groups
  Health checks are at the target group level

Good to Know:
- Fixed hostname
• The application servers don’t see the IP of the client directly
	• The true IP of the client is inserted in the header X-Forwarded-For
	• We can also get Port (X-Forwarded-Port) and proto (X-Forwarded-Proto) (for protocol)
> When cline talks to ELB it performs something like connection termination and forward requests to lets say an instance with information in headers.


**Network Load Balancer:** Layer 4
- Forward TCP & UDP traffic to your instances
- Handle millions of request per seconds
- Less latency ~100 ms (vs 400 ms for ALB)
- Not in free tier.
- ELB creates network interfaces for each enabled Availability Zone.
- Load balancer nodes in a zone use these interfaces for static IP addresses.
- Internet-facing ELBs can associate an Elastic IP per subnet
- It can only have layer 4 listeners but can route HTTP traffic treating it as layer 4.
- Has static IP and DNS name both.

Target groups:
1. EC2 instances
2. Ip addresses: private
3. ALB
Why use ALB as target group?
As we know that NLB can  route HTTP traffic treating it as layer 4.
- Combining an Application Load Balancer (ALB) with a Network Load Balancer (NLB) offers enhanced traffic routing capabilities.
- ALB provides layer 7 features like path-based and host-based routing for application-level traffic management.
- NLB excels at layer 4 transport-level routing, handling TCP and UDP traffic efficiently.
- Utilizing ALB as a target group for NLB enables advanced content-based distribution and complex routing scenarios.

Health Checks:
- support TCP, HTTP, HTTPs protocols.
- the NLB supports HTTP health checks as well as TCP and HTTPS

Gateway load balancers: Layer 3, IP packets, GENEVE protocol on 6081
Why use it:
- If we want our traffic to go trough:
	- Firewalls, Intrusion Detection and
	- Prevention Systems, Deep Packet Inspection
	- Systems, payload manipulation
- We can have 3rd party services(virtual appliances) to check the traffic.
![[Pasted image 20230817021705.png]]
Functions:
• Transparent Network Gateway – single entry/exit for all traffic
• Load Balancer – distributes traffic to your virtual appliances

target groups:
1. EC2
2. Ip addresses- private

Sticky session: Session affinity
This works for Classic Load Balancer, Application Load Balancer, and Network Load Balancer
- A cookie is sent from client to load balancer.
- it may bring imbalance to the load balancing.
Cookies:
- **Application-based Cookies:**
  - **Custom Cookie:**
    - Generated by the target (application)
    - Can include application-specific attributes.
    - Specify cookie name for each target group.
    - Avoid reserved names like AWSALB, AWSALBAPP, AWSALBTG.
  - **Application Cookie:**
    - Generated by the load balancer.
    - Cookie name: AWSALBAPP.
- **Duration-based Cookies:**
  - Generated by the load balancer.
  - Cookie name: AWSALB (ALB), AWSELB (CLB).

Cross Zone load balancing:
With Cross Zone Load Balancing: each load balancer instance distributes evenly across all registered instances in all AZ
Without Cross Zone Load Balancing: Requests are distributed in the instances of the node of the Elastic Load Balancer
For Application load balancer:
1. by default cross zone enabled.
2. no charges for inter AZ data transfer.(generally inter AZ is charged in AWS)
For Network Load balancer:
1. Disabled by default.
2. Charges for inter AZ data transfer if enabled.
For Classic Load balancer:
1. Disabled by default.
2. No Charges for inter AZ data transfer if enabled.

SSL/TLS certificates:
- allows traffic between your clients and your load balancer to be encrypted in transit (in-flight encryption).
- Data will be encrypted and will only be decrypted by receiver.
- Certificates have expiration date(we set) and must be renewed

>SSL: Secure Socket layer: secure connection
  TLS: Transport Layer Security
  Public SSL: Certificate Authorities: Comodo, Symantec, GoDaddy

Process:
1. Clients talk to LB over internet with HTTPS, ssl certificate.
	1. The load balancer uses an X.509 certificate (SSL/TLS server certificate)
	2. You can manage certificates using ACM (AWS Certificate Manager)
	3. You can upload your own certificates alternatively
	4. While setting up HTTPS listener.
		1. You must specify a default certificate
		2. You can add an optional list of certs to support multiple domains
		3. Clients can use SNI (Server Name Indication) to specify the hostname they reach
		4. Ability to specify a security policy to support older versions of SSL / TLS (legacy clients)
2. LB does something called SSL termination.
3. LB talks to EC2 over private network with HTTP


SNI: Server name Indication: for both ALB, NLB
So whenever client is doing SSL handshake, generally if server has only one website, it knows what SSL certificate to load cos there is only one website hosted on server.

But if there are multiple website hosted on server, during SSL handshake with client, how will server know what certificate to load?
A: Solves SSL certificate loading issue for multiple websites on one server.
Process:
- Requires client to indicate hostname in SSL handshake.
- Server finds correct certificate or returns default.
- Works for ALB, NLB, CloudFront (newer generation).
- Not applicable for CLB (older generation).

> This allows LB to have multiple certificates for multiple target groups behind it.
> Classic Load Balancer (v1)
		- Support only one SSL certificate
		- Must use multiple CLB for multiple hostname with multiple SSL certificates
	Application Load Balancer (v2)
		- Supports multiple listeners with multiple SSL certificates
		- Uses Server Name Indication (SNI) to make it work
	Network Load Balancer (v2)
		- Supports multiple listeners with multiple SSL certificates
		- Uses Server Name Indication (SNI) to make it work

Connection Draining/Deregistration Delay:
Connection Draining: CLB
Deregistration Delay: ALB & NLB

- So when LB finds that an instance is  unhealthy, then the instance is in draining/de-registering period.
- LB wont allow new connections for that instance.
- However, 'in-flight requests' will be given time to be completed.
- This time is 1-3600 seconds, default 300 seconds, disabled == 0
- if request is short, set to low value.
- if time is high value, then instance will take long to go away,

ASG:
Auto Scaling Group (ASG) Features:
- Scale out to handle increased load by adding EC2 instances.
- Scale in to match decreased load by removing EC2 instances.
- Set minimum and maximum instances for scaling.
- Automatically register new instances to a load balancer.
- Re-create terminated instances(unhealthy ones, terminated by maybe LB) for maintaining desired capacity.
- ASGs are free, with charges only for EC2 instances.

> Desired capacity: number of instances you want.

Attributes: It needs
- Launch Template Features:
	- Contains AMI and instance type information.
	-  EC2 user data
	- EBS volumes, security groups, SSH key pair, IAM roles.
	- Specifies network and subnet details.
	- Can include load balancer information.
- Sets minimum, maximum, and initial capacity for Auto Scaling.
- Defines scaling policies for automatic scaling.

> We can also scale in and out based on cloudwatch alarms.
> a metric is monitored, adn when it is too high alarm is triggered.

Scaling Policies:
Dynamic:
- **Target Tracking Scaling:** Maintains a specific metric at a desired value (e.g., CPU at 40%).
- **Simple / Step Scaling:** Adds or removes units based on CloudWatch alarms (e.g., CPU > 70% adds 2 units).
- **Scheduled Actions:** Pre-planned scaling actions (e.g., increase min capacity to 10 at 5 pm on Fridays).
Predictive Scaling:
- history is analyzed and forecast is generated.

What metrics should be used as factors to feed to Cloudwatch or ASG to scale in/out?
A: 
1. CPU utilization
2. Request count per target: request each instance is getting in target group.
3. Average network:
	1. if app needs upload/download
	2. then in/out network can be a metric.

Scaling Cool down (default 300 seconds):
After trigger from metric and scaling in/out, ASG enters a cooling down period where it wont launch/terminate new instances.
Why? to let the metric stabilized.

> Ready to use AMIs:
> 	1. reduces config time.
> 	2. reduces cool down period
> 		1. these AMIs are pre-configured, the process of launching new instances is streamlined, allowing you to add or remove instances from an Auto Scaling group more rapidly.
> 		2. Instances launched from these AMIs can be terminated without the need to manually remove installed software or configurations.
> 	3. serves request faster.





